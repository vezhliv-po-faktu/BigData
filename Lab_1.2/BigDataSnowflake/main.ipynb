{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контейнером"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поднять контейнера в фоне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN\u001b[0m[0000] The \"POSTGRES_USER\" variable is not set. Defaulting to a blank string. \n",
      "\u001b[33mWARN\u001b[0m[0000] The \"POSTGRES_DB\" variable is not set. Defaulting to a blank string. \n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/2\n",
      " \u001b[32m✔\u001b[0m Network bigdatasnowflake_default  \u001b[32mCreated\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[33m⠋\u001b[0m Container bigdatasnowflake-db-1   Creating                              \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
      " \u001b[32m✔\u001b[0m Network bigdatasnowflake_default  \u001b[32mCreated\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[33m⠙\u001b[0m Container bigdatasnowflake-db-1   Starting                              \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
      " \u001b[32m✔\u001b[0m Network bigdatasnowflake_default  \u001b[32mCreated\u001b[0m                               \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container bigdatasnowflake-db-1   \u001b[32mStarted\u001b[0m                               \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остановка контейнера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN\u001b[0m[0000] The \"POSTGRES_USER\" variable is not set. Defaulting to a blank string. \n",
      "\u001b[33mWARN\u001b[0m[0000] The \"POSTGRES_DB\" variable is not set. Defaulting to a blank string. \n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠋\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠙\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠹\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.3s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠸\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.4s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠼\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.5s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠴\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.6s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠦\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.7s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 0/1\n",
      " \u001b[33m⠧\u001b[0m Container bigdatasnowflake-db-1  S...                                   \u001b[34m0.8s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 1/2\u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container bigdatasnowflake-db-1   \u001b[32mRemoved\u001b[0m                               \u001b[34m0.8s \u001b[0m\n",
      " \u001b[33m⠋\u001b[0m Network bigdatasnowflake_default  Removing                              \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Running 1/2\n",
      " \u001b[32m✔\u001b[0m Container bigdatasnowflake-db-1   \u001b[32mRemoved\u001b[0m                               \u001b[34m0.8s \u001b[0m\n",
      " \u001b[33m⠙\u001b[0m Network bigdatasnowflake_default  Removing                              \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l\u001b[34m[+] Running 2/2\u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container bigdatasnowflake-db-1   \u001b[32mRemoved\u001b[0m                               \u001b[34m0.8s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Network bigdatasnowflake_default  \u001b[32mRemoved\u001b[0m                               \u001b[34m0.2s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker-compose down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть логи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключения к БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_USER = \"postgres\"\n",
    "DB_PASS = \"highload\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\" \n",
    "DB_NAME = \"highload_db\"\n",
    "CONN_URL = f\"postgresql+asyncpg://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "ECHO = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создам класс `DBManager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DBManager(db_url='postgresql+asyncpg://bober:bober_kurwa@localhost:5432/bober_db')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from contextlib import asynccontextmanager\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.ext.asyncio import (\n",
    "    create_async_engine,\n",
    "    AsyncSession,\n",
    "    AsyncEngine,\n",
    "    async_sessionmaker,\n",
    ")\n",
    "from typing import AsyncGenerator, Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DBManager:\n",
    "    def __init__(self, db_url: str, pool_size: int = 5, max_overflow: int = 10, echo: bool = True):\n",
    "        self.db_url: str = db_url\n",
    "        try:\n",
    "            self.engine: AsyncEngine = create_async_engine(\n",
    "                self.db_url,\n",
    "                pool_size=pool_size,\n",
    "                max_overflow=max_overflow,\n",
    "                echo=echo,\n",
    "                pool_recycle=3600,\n",
    "            )\n",
    "            \n",
    "            self._session_factory: async_sessionmaker[AsyncSession] = async_sessionmaker(\n",
    "                bind=self.engine,\n",
    "                expire_on_commit=False,  # important for async sessions\n",
    "            )\n",
    "            \n",
    "        except ImportError as ie:\n",
    "            raise ImportError(f\"Ошибка драйвера: {ie}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Ошибка движка: {e}\")\n",
    "    \n",
    "    \n",
    "    @asynccontextmanager\n",
    "    async def get_session(self) -> AsyncGenerator[AsyncSession, None]:\n",
    "        session: AsyncSession = self._session_factory()\n",
    "        try:\n",
    "            yield session\n",
    "            await session.commit()\n",
    "        except Exception as e:\n",
    "            await session.rollback()\n",
    "            raise RuntimeError(f\"Ошибка запроса к базе данных: {e}\")\n",
    "        finally:\n",
    "            await session.close()\n",
    "\n",
    "    \n",
    "    async def create_tables_from_csv(self, file_csv: Union[Path, str]) -> bool:\n",
    "        try:\n",
    "            if isinstance(file_csv, str):\n",
    "                file_csv = Path(file_csv)\n",
    "\n",
    "            df = pd.read_csv(file_csv)\n",
    "            # table_name = file_csv.stem\n",
    "            table_name = \"mock_data\"\n",
    "\n",
    "            # Используем напрямую async engine (а не session)\n",
    "            async with self.engine.begin() as conn:\n",
    "                await conn.run_sync(\n",
    "                    lambda sync_conn: df.to_sql(\n",
    "                        name=table_name,\n",
    "                        con=sync_conn,\n",
    "                        if_exists='append',\n",
    "                        index=False\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print(f\"Таблица '{table_name}' успешно загружена.\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Критическая ошибка при загрузке CSV: {e}\")\n",
    "            print(f\"Не удалось создать таблицу из файла {file_csv.name}.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    async def execute_sql_file(self, sql_file: Union[Path, str]) -> Union[str, bool]:\n",
    "        \"\"\"\n",
    "        Выполняет SQL файл асинхронно с поддержкой нескольких запросов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isinstance(sql_file, str):\n",
    "                sql_file = Path(sql_file)\n",
    "            \n",
    "            if not sql_file.exists():\n",
    "                raise FileNotFoundError(f\"SQL файл не найден: {sql_file}\")\n",
    "            \n",
    "            sql_content = sql_file.read_text(encoding='utf-8').strip()\n",
    "            if not sql_content:\n",
    "                print(\"SQL файл пуст\")\n",
    "                return False\n",
    "            \n",
    "            queries = [q.strip() for q in sql_content.split(';') if q.strip()]\n",
    "            \n",
    "            if not queries:\n",
    "                print(\"Не найдено валидных SQL запросов\")\n",
    "                return False\n",
    "            \n",
    "            results = []\n",
    "            successful_queries = 0\n",
    "            \n",
    "            for i, query in enumerate(queries, 1):\n",
    "                if not query or query.strip().startswith('--'):\n",
    "                    continue\n",
    "                \n",
    "                print(f\"\\n--- Запрос {i}/{len(queries)} ---\")\n",
    "                print(f\"SQL: {query[:100]}...\")\n",
    "                \n",
    "                try:\n",
    "                    clean_query = \" \".join(line for line in query.splitlines() \n",
    "                                        if not line.strip().startswith('--'))\n",
    "                    clean_query = clean_query.strip()\n",
    "                    \n",
    "                    first_word = clean_query.split()[0].upper() if clean_query.split() else \"\"\n",
    "                    is_select = first_word == 'SELECT'\n",
    "                    \n",
    "                    print(f\"Тип запроса: {first_word}\")\n",
    "                    \n",
    "                    if first_word in ['DROP', 'CREATE', 'ALTER', 'TRUNCATE']:\n",
    "                        # DDL запросы - используем begin() который автоматически коммитит\n",
    "                        print(\"Выполнение DDL запроса...\")\n",
    "                        async with self.engine.begin() as conn:\n",
    "                            result = await conn.execute(text(query))\n",
    "                            print(f\"DDL выполнен, результат: {result}\")\n",
    "                        results.append(f\"DDL запрос {i} выполнен успешно\\n\")\n",
    "                        successful_queries += 1\n",
    "                        print(\"✓ DDL запрос завершен\")\n",
    "                        \n",
    "                    elif is_select:\n",
    "                        print(\"Выполнение SELECT запроса...\")\n",
    "                        async with self.get_session() as session:\n",
    "                            result = await session.execute(text(query))\n",
    "                            rows = result.fetchall()\n",
    "                            \n",
    "                            if rows:\n",
    "                                df = pd.DataFrame(rows, columns=result.keys())\n",
    "                                results.append(f\"Результат запроса {i}:\\n{df.to_string(index=False)}\\n\")\n",
    "                                print(f\"Найдено строк: {len(rows)}\")\n",
    "                            else:\n",
    "                                results.append(f\"Запрос {i} выполнен, но данных не найдено\\n\")\n",
    "                                print(\"Данные не найдены\")\n",
    "                            successful_queries += 1\n",
    "                    else:\n",
    "                        # DML запросы (INSERT, UPDATE, DELETE)\n",
    "                        print(\"Выполнение DML запроса...\")\n",
    "                        async with self.get_session() as session:\n",
    "                            result = await session.execute(text(query))\n",
    "                            await session.commit()\n",
    "                            print(f\"DML выполнен, затронуто строк: {result.rowcount}\")\n",
    "                        results.append(f\"DML запрос {i} выполнен успешно\\n\")\n",
    "                        successful_queries += 1\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Ошибка в запросе {i}: {e}\"\n",
    "                    print(f\"✗ Ошибка: {error_msg}\")\n",
    "                    results.append(error_msg + \"\\n\")\n",
    "                    continue\n",
    "            \n",
    "            # Проверим, какие таблицы действительно создались\n",
    "            print(\"\\n=== ПРОВЕРКА СОЗДАННЫХ ТАБЛИЦ ===\")\n",
    "            async with self.get_session() as session:\n",
    "                try:\n",
    "                    result = await session.execute(text(\"\"\"\n",
    "                        SELECT table_name \n",
    "                        FROM information_schema.tables \n",
    "                        WHERE table_schema = 'public'\n",
    "                        ORDER BY table_name\n",
    "                    \"\"\"))\n",
    "                    tables = result.fetchall()\n",
    "                    print(f\"Таблиц в базе: {len(tables)}\")\n",
    "                    for table in tables:\n",
    "                        print(f\"  - {table[0]}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка при проверке таблиц: {e}\")\n",
    "            \n",
    "            final_result = \"\\n\".join(results)\n",
    "            print(f\"\\nИТОГ: Выполнено {successful_queries}/{len(queries)} запросов\")\n",
    "            \n",
    "            if any(\"Результат запроса\" in str(res) for res in results):\n",
    "                return final_result\n",
    "            else:\n",
    "                return successful_queries == len(queries)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Критическая ошибка при выполнении SQL файла: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<DBManager(db_url='{self.db_url}')>\"\n",
    "        \n",
    "        \n",
    "db = DBManager(db_url=CONN_URL, echo=ECHO)\n",
    "db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Создание стурктуры БД из директории `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# файлы с данными в формате csv\n",
    "DATA_DIR = Path(\"./data\")\n",
    "CSV_FILES = list(DATA_DIR.glob(\"*.csv\"))\n",
    "\n",
    "# файлы с sql скриптами\n",
    "SCRIPTS_DIR =  Path(\"./sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA.csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (1).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (6).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (7).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (8).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (4).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (5).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (9).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (2).csv успешно создана.\n",
      "Таблица 'mock_data' успешно загружена.\n",
      "Таблица из файла MOCK_DATA (3).csv успешно создана.\n"
     ]
    }
   ],
   "source": [
    "async def create_tables():\n",
    "    # Создадим таблички из csv файлов\n",
    "    for file in CSV_FILES:\n",
    "        success = await db.create_tables_from_csv(file)\n",
    "        if success:\n",
    "            print(f\"Таблица из файла {file.name} успешно создана.\")\n",
    "        else:\n",
    "            print(f\"Не удалось создать таблицу из файла {file.name}.\")\n",
    "\n",
    "\n",
    "await create_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во строк после загрузки из `csv` файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Запрос 1/2 ---\n",
      "SQL: SELECT count(*) FROM mock_data md...\n",
      "Тип запроса: SELECT\n",
      "Выполнение SELECT запроса...\n",
      "Найдено строк: 1\n",
      "\n",
      "=== ПРОВЕРКА СОЗДАННЫХ ТАБЛИЦ ===\n",
      "Таблиц в базе: 1\n",
      "  - mock_data\n",
      "\n",
      "ИТОГ: Выполнено 1/2 запросов\n",
      "Результат запроса 1:\n",
      " count\n",
      " 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await db.execute_sql_file(SCRIPTS_DIR / \"check_count_rows.sql\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбцы, которые появились в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Запрос 1/2 ---\n",
      "SQL: select string_agg(column_name, ', ') from information_schema.\"columns\" c \n",
      "where c.table_schema = 'pu...\n",
      "Тип запроса: SELECT\n",
      "Выполнение SELECT запроса...\n",
      "Найдено строк: 1\n",
      "\n",
      "--- Запрос 2/2 ---\n",
      "SQL: select column_name\n",
      "from information_schema.\"columns\" c \n",
      "where c.table_schema = 'public'\n",
      "and c.table_...\n",
      "Тип запроса: SELECT\n",
      "Выполнение SELECT запроса...\n",
      "Найдено строк: 50\n",
      "\n",
      "=== ПРОВЕРКА СОЗДАННЫХ ТАБЛИЦ ===\n",
      "Таблиц в базе: 1\n",
      "  - mock_data\n",
      "\n",
      "ИТОГ: Выполнено 2/2 запросов\n",
      "Результат запроса 1:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       string_agg\n",
      "id, customer_first_name, customer_last_name, customer_age, customer_email, customer_country, customer_postal_code, customer_pet_type, customer_pet_name, customer_pet_breed, seller_first_name, seller_last_name, seller_email, seller_country, seller_postal_code, product_name, product_category, product_price, product_quantity, sale_date, sale_customer_id, sale_seller_id, sale_product_id, sale_quantity, sale_total_price, store_name, store_location, store_city, store_state, store_country, store_phone, store_email, pet_category, product_weight, product_color, product_size, product_brand, product_material, product_description, product_rating, product_reviews, product_release_date, product_expiry_date, supplier_name, supplier_contact, supplier_email, supplier_phone, supplier_address, supplier_city, supplier_country\n",
      "\n",
      "Результат запроса 2:\n",
      "         column_name\n",
      "                  id\n",
      " customer_first_name\n",
      "  customer_last_name\n",
      "        customer_age\n",
      "      customer_email\n",
      "    customer_country\n",
      "customer_postal_code\n",
      "   customer_pet_type\n",
      "   customer_pet_name\n",
      "  customer_pet_breed\n",
      "   seller_first_name\n",
      "    seller_last_name\n",
      "        seller_email\n",
      "      seller_country\n",
      "  seller_postal_code\n",
      "        product_name\n",
      "    product_category\n",
      "       product_price\n",
      "    product_quantity\n",
      "           sale_date\n",
      "    sale_customer_id\n",
      "      sale_seller_id\n",
      "     sale_product_id\n",
      "       sale_quantity\n",
      "    sale_total_price\n",
      "          store_name\n",
      "      store_location\n",
      "          store_city\n",
      "         store_state\n",
      "       store_country\n",
      "         store_phone\n",
      "         store_email\n",
      "        pet_category\n",
      "      product_weight\n",
      "       product_color\n",
      "        product_size\n",
      "       product_brand\n",
      "    product_material\n",
      " product_description\n",
      "      product_rating\n",
      "     product_reviews\n",
      "product_release_date\n",
      " product_expiry_date\n",
      "       supplier_name\n",
      "    supplier_contact\n",
      "      supplier_email\n",
      "      supplier_phone\n",
      "    supplier_address\n",
      "       supplier_city\n",
      "    supplier_country\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await db.execute_sql_file(SCRIPTS_DIR / \"select_all_rows.sql\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
